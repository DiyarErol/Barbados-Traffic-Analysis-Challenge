"""
Improved Submission Generator using Train Data Patterns
Uses statistical patterns from training data for better predictions
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.ensemble import GradientBoostingClassifier

def analyze_train_patterns():
    """Analyze training data to understand patterns"""
    
    print('='*60)
    print('ğŸ“Š TRAIN VERÄ°SÄ° PATTERN ANALÄ°ZÄ°')
    print('='*60)
    
    # Load train data
    train_df = pd.read_csv('Train.csv')
    train_df['datetime'] = pd.to_datetime(train_df['datetimestamp_start'])
    train_df['hour'] = train_df['datetime'].dt.hour
    train_df['day_of_week'] = train_df['datetime'].dt.dayofweek
    
    # Analyze congestion by hour
    print('\nğŸ• Saate GÃ¶re TÄ±kanÄ±klÄ±k OranlarÄ±:')
    hour_enter = train_df.groupby('hour')['congestion_enter_rating'].value_counts(normalize=True).unstack(fill_value=0)
    hour_exit = train_df.groupby('hour')['congestion_exit_rating'].value_counts(normalize=True).unstack(fill_value=0)
    
    return hour_enter, hour_exit, train_df


def generate_smart_submission():
    """Generate submission using intelligent pattern matching"""
    
    print('\n' + '='*60)
    print('ğŸ¯ AKILLI SUBMISSION GENERATOR')
    print('='*60)
    
    # Analyze patterns
    hour_enter_prob, hour_exit_prob, train_df = analyze_train_patterns()
    
    # Load sample submission
    print('\nğŸ“ Sample submission yÃ¼kleniyor...')
    sample_df = pd.read_csv('SampleSubmission.csv')
    required_ids = sample_df['ID'].tolist()
    print(f'âœ“ Gerekli ID sayÄ±sÄ±: {len(required_ids):,}')
    
    # Load models
    print('\nğŸ¤– Model yÃ¼kleniyor...')
    try:
        enter_model = joblib.load('voting_ensemble_enter_model.pkl')
        exit_model = joblib.load('voting_ensemble_exit_model.pkl')
        print(f'âœ“ Model yÃ¼klendi: Voting Ensemble')
    except:
        print('âš ï¸ Ensemble model bulunamadÄ±, yeni model eÄŸitiliyor...')
        
        # Prepare features
        train_df['is_rush_hour'] = train_df['hour'].isin([7, 8, 9, 16, 17, 18]).astype(int)
        train_df['is_weekend'] = (train_df['day_of_week'] >= 5).astype(int)
        
        # Simple features
        feature_cols = ['hour', 'is_rush_hour', 'day_of_week', 'is_weekend']
        X = train_df[feature_cols]
        
        # Encode targets
        from sklearn.preprocessing import LabelEncoder
        le_enter = LabelEncoder()
        le_exit = LabelEncoder()
        
        y_enter = le_enter.fit_transform(train_df['congestion_enter_rating'])
        y_exit = le_exit.fit_transform(train_df['congestion_exit_rating'])
        
        # Train models
        enter_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
        exit_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
        
        enter_model.fit(X, y_enter)
        exit_model.fit(X, y_exit)
        
        # Save label encoders for later use
        import pickle
        with open('label_encoders.pkl', 'wb') as f:
            pickle.dump({'enter': le_enter, 'exit': le_exit}, f)
    
    # Load label encoders
    try:
        import pickle
        with open('label_encoders.pkl', 'rb') as f:
            label_encoders = pickle.load(f)
            le_enter = label_encoders['enter']
            le_exit = label_encoders['exit']
    except:
        # Create default mapping
        le_enter = None
        le_exit = None
    
    # Generate predictions
    print('\nğŸ”® Tahminler oluÅŸturuluyor...')
    submission_data = []
    
    congestion_map = {
        0: 'free flowing',
        1: 'light delay',
        2: 'moderate delay',
        3: 'heavy delay'
    }
    
    for req_id in required_ids:
        try:
            # Parse ID
            parts = req_id.split('_')
            segment_id = int(parts[2])
            rating_type = parts[-2]  # 'enter' or 'exit'
            
            # Estimate hour from segment_id
            hour = (segment_id // 60) % 24
            day_of_week = (segment_id // 1440) % 7
            is_rush_hour = 1 if hour in [7, 8, 9, 16, 17, 18] else 0
            is_weekend = 1 if day_of_week >= 5 else 0
            
            # Create features
            features = pd.DataFrame([{
                'hour': hour,
                'is_rush_hour': is_rush_hour,
                'day_of_week': day_of_week,
                'is_weekend': is_weekend
            }])
            
            # Predict
            if rating_type == 'enter':
                pred_num = enter_model.predict(features)[0]
                if le_enter is not None:
                    prediction = le_enter.inverse_transform([pred_num])[0]
                else:
                    prediction = congestion_map.get(pred_num, 'free flowing')
            else:
                pred_num = exit_model.predict(features)[0]
                if le_exit is not None:
                    prediction = le_exit.inverse_transform([pred_num])[0]
                else:
                    prediction = congestion_map.get(pred_num, 'free flowing')
            
            # Ensure valid congestion level
            if prediction not in congestion_map.values():
                prediction = 'free flowing'
                
        except Exception as e:
            # Default prediction
            prediction = 'free flowing'
        
        submission_data.append({
            'ID': req_id,
            'Target': prediction,
            'Target_Accuracy': prediction
        })
    
    submission_df = pd.DataFrame(submission_data)
    
    # Save
    output_file = 'submission.csv'
    submission_df.to_csv(output_file, index=False)
    
    print(f'\nâœ… Submission oluÅŸturuldu: {output_file}')
    print(f'ğŸ“Š Toplam satÄ±r: {len(submission_df):,}')
    
    # Show distribution
    print(f'\nğŸ“ˆ Tahmin DaÄŸÄ±lÄ±mÄ±:')
    dist = submission_df['Target'].value_counts()
    for label, count in dist.items():
        pct = count / len(submission_df) * 100
        print(f'   {label}: {count:,} ({pct:.1f}%)')
    
    # Validate
    print(f'\nâœ… Validasyon:')
    print(f'   TÃ¼m ID\'ler mevcut: {len(submission_df) == len(sample_df)}')
    print(f'   Format doÄŸru: {list(submission_df.columns) == list(sample_df.columns)}')
    
    # Check for invalid predictions
    invalid = submission_df[~submission_df['Target'].isin(congestion_map.values())]
    if len(invalid) > 0:
        print(f'   âš ï¸ GeÃ§ersiz tahmin: {len(invalid)}')
    else:
        print(f'   âœ“ TÃ¼m tahminler geÃ§erli')
    
    return submission_df


if __name__ == '__main__':
    submission = generate_smart_submission()
    
    print('\n' + '='*60)
    print('âœ… SUBMISSION HAZIR!')
    print('='*60)
    print('\nğŸ“¤ Zindi\'ye yÃ¼klenmeye hazÄ±r: submission.csv')
    print('ğŸ”— https://zindi.africa/competitions/barbados-traffic-analysis-challenge/submissions')
